{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZMjNacnZ46Td"
   },
   "source": [
    "# Important Python packages and how to use them\n",
    "\n",
    "A big part of pythons 'power' is the vast availability of packages for nearly everything.\n",
    "If you want to do anything with python, it is always worth a quick look at google whether there\n",
    "is a package which is doing just that.\n",
    "\n",
    "### important packages we will discuss:\n",
    "\n",
    "- scipy: a lot of features for curve fitting, integration, solving differential equations, statistics, ...\n",
    "- numpy: handling of numpy arrays for fast processing of large data arrays. Implements a lot of mathematical functions -> usage highly recommended for any sort of math task\n",
    "- matplotlib: for plots of all sort\n",
    "- pandas: import and export of data from nearly any form, performing statistics, grouping, applying functions on whole data sets, ... very mighty data tool!\n",
    "- seaborn: easy and powerful data visualisation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rCFqLSY46Tg"
   },
   "source": [
    "### important packages we will not discuss in this tutorial:\n",
    "\n",
    "- os: comes with some useful methods to create directories, change the current working directory, join paths platform independently, check for the existence of files, ...\n",
    "- sys: lets you use arguments passed to a python script via console, controls the stdout flow, check the operating system, ...\n",
    "- uncertainties: easy error propagation \n",
    "- pickle: store binary data (like trained learner from machine learning) or whatever else\n",
    "- scikit-learn: machine learning package\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WCC9cq0r46Tl"
   },
   "source": [
    "## 1. import\n",
    "Packages can be imported with the import keyword.\n",
    "For some packages there is a common alias like np for numpy. You can specify an alias as shown below. To import only a certain module from a package or only a function or class from a module, you can do so as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrqtgWkW46Tq"
   },
   "outputs": [],
   "source": [
    "# packages are included this way:\n",
    "import numpy\n",
    "\n",
    "# you can give an 'alias' to imported packages\n",
    "import numpy as np\n",
    "\n",
    "# you can import certain methods or classes from a package\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mnOJH85P46T-"
   },
   "source": [
    "## 2. numpy: numerical python\n",
    "\n",
    "There is nearly always the need of processing arrays of numbers. If you use arrays, you should \"always\" use numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pig5uLR-46UA"
   },
   "outputs": [],
   "source": [
    "# the numpy array is always recommended to use when it is about doing something with arrays\n",
    "a = np.array([1,2,3,4])\n",
    "\n",
    "print(a)\n",
    "\n",
    "# the handling is quite similar to lists\n",
    "print(a[-2:-1]) # the slicing means [-2:-2:]\n",
    "\n",
    "# very useful: functions executed with numpy arrays act on each entry normally without code changes:\n",
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "# a big exception are if statements, which wont work as expected on arrays!\n",
    "\n",
    "print(f(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ib51yrzA46UL"
   },
   "source": [
    "### numpy - some important features\n",
    "These are some methods you will need quite sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yObYkbeS46UO"
   },
   "outputs": [],
   "source": [
    "# important features:\n",
    "\n",
    "# array of length 4 filled with zeros\n",
    "a = np.zeros(4)\n",
    "print(a)\n",
    "\n",
    "# array of length 3 filled with ones\n",
    "b = np.ones(3)\n",
    "print(b)\n",
    "\n",
    "\n",
    "# matrix of zeros with the size 3x4, meaning there will be 3 rows and 4 columns\n",
    "a = np.zeros((3,4))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M50BccAS46UW"
   },
   "outputs": [],
   "source": [
    "# linear distributed numbers between start and end (end included)\n",
    "# the third argument gives the length\n",
    "x = np.linspace(0, 10, 21)\n",
    "print('x =', x)\n",
    "\n",
    "# exponentially distributed numbers with the exponents from lower to higher\n",
    "# this means from 1*10**1 = 10 up to 1*10**5 = 100000\n",
    "y = np.logspace(1, 5, 11)\n",
    "print('y =', y)\n",
    "\n",
    "# numbers between low (included) and high (excluded) with stepwidth as third argument\n",
    "k = np.arange(0, 16, 3)\n",
    "print('k =', k)\n",
    "\n",
    "# many functions for arrays are efficiently implemented in numpy\n",
    "y = np.exp(x)\n",
    "print('np.exp(x) =', y)\n",
    "\n",
    "#similar: np.log, np.sqrt, np.sin, np.cos,.........\n",
    "\n",
    "\n",
    "# in np.random there are several random generators, for example normal, uniform, poisson, ...\n",
    "x = np.random.normal(0, 1, 10) #this means, the mean of the distribution is 0, the sigma is 1 and we generate 10 numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BNXLhFs346Uh"
   },
   "source": [
    "### masking\n",
    "Very often you want to \"filter\" an array by a value e.g. all values larger than a certain threshold. This can be done very easily!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zt3hSc9h46Uk"
   },
   "outputs": [],
   "source": [
    "# very useful for slicing\n",
    "print('gaussian distributed x =', x)\n",
    "print('Is x>0.2?', x>0.2)\n",
    "print('The numbers with x>0.2 are ',x[x>0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NC7IhGvc46Uv"
   },
   "outputs": [],
   "source": [
    "# often overlooked but an extremely powerful tool:\n",
    "x = np.arange(-5, 5)\n",
    "print(\"Values: \", x)\n",
    "\n",
    "# entry-wise if evaluation\n",
    "# you can chain multiple evaluations with \n",
    "# AND: (first condition in brackets) & (second condition in brackets)\n",
    "# OR: (first condition in brackets) | (second condition in brackets)\n",
    "print(\"Values are below zeros at these indices: \", np.where(x < 0)[0])\n",
    "# you can also apply a function to the parts of the array where the condition is True or False\n",
    "print(\"Rectified values: \", np.where(x < 0, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRxovItc46U3"
   },
   "source": [
    "## 3. matplotlib\n",
    "matplotlib is a quite flexible library for easy plot creation. Usually pyplot from matplotlib is imported with the alias plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RPuC4_e_46U4"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fill a histogram with the created numbers and show the histogram\n",
    "x = np.random.normal(0, 1, 10)\n",
    "plt.hist(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A9z5TQ5E46VB"
   },
   "source": [
    "### python histograms\n",
    "python sees histograms not quite as the same thing like for example root. In python they are stored and handles as a collection of:\n",
    "> (bin edges, bin contents, \"drawn\" bars for display)\n",
    "<br>\n",
    "\n",
    "You can get these from the function call of plt.hist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gx-uVn3S46VC"
   },
   "outputs": [],
   "source": [
    "things = plt.hist(x)\n",
    "print(things)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RrFHoHvG46VK"
   },
   "source": [
    "### Example 3.1: Distributions and histograms\n",
    "\n",
    "Look up another distribution available from numpy random. Generate some data points, fill them into a histogram and show it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cwj158tW46VT"
   },
   "source": [
    "### plot with matplotlib\n",
    "This is an example of a more \"complex\" plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SKUAKGBs46VU"
   },
   "outputs": [],
   "source": [
    "# lets create an array and calc some formula on it\n",
    "x = np.linspace(-4, 4) # remember: create 50 equally dirstibuted numbers between -4 and 4\n",
    "y = x**2\n",
    "\n",
    "# get a figure and specify the size (in inches ...)\n",
    "# first number corresponds to the width, second to the height\n",
    "# dpi are \"dots per inch\" and refer to image quality\n",
    "# 300 is good for printing (like a thesis), but you should prefer pdf files for this anyway\n",
    "f = plt.figure(figsize=(6,4), dpi=300) \n",
    "\n",
    "# plot the values, add a 'style' and a label\n",
    "plt.plot(x, y, 'k+', label = '$f(x) = x^2$') # k stands for black, the + will plot a + as the marker\n",
    "\n",
    "# add labels to the axis\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "\n",
    "# add a legend to the best position\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# activate the grid (True optional as argument)\n",
    "plt.grid()\n",
    "\n",
    "# make things look nice if something has gone wrong\n",
    "plt.tight_layout()\n",
    "\n",
    "# save to file\n",
    "plt.savefig('plot.png')\n",
    "\n",
    "# show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "314SH95g46Vb"
   },
   "source": [
    "### Example 3.2: Enhance your histograms\n",
    "Add a label, x- and y- axis labels and a legend to your histograms. Use a different color and save it.\n",
    "### Example 3.3: Red dotted sine function\n",
    "Create an array from 0 to 2pi (np.pi is available ...) and compute the sine function of it. Plot it to a canvas using a red dashed line.\n",
    "\n",
    "### Example 3.4: Slicing plots\n",
    "Plot positive values black, negative ones red.\n",
    "\n",
    "### Example 3.5: Add gaussian noise\n",
    "Add gaussian noise to the sine plot and use the same color for all data points again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IPcKEXP146Vd"
   },
   "source": [
    "### errorbar\n",
    "For many plots in physics you need to also show the uncertainties of a given value. This can be done with the errorbar method, parsing the uncertainties as yerr=values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-7Jq-iEp46Vf"
   },
   "outputs": [],
   "source": [
    "# another very important 'plotstyle': errorbar\n",
    "\n",
    "# get another figure\n",
    "plt.figure(figsize=(6,4), dpi=300)\n",
    "\n",
    "# the hist function returns the bin contents, the bin edges and the histogram itself\n",
    "x = np.random.normal(0, 1, 1000)\n",
    "content, edges, hist = plt.hist(x, label='histogram')\n",
    "#print(edges)\n",
    "#print(edges[:-1])\n",
    "#print(edges[1:])\n",
    "#print((edges[:-1]+edges[1:])/2)\n",
    "\n",
    "# add the errorbar plot\n",
    "# the style is specified using the fmt argument\n",
    "## we need the bin middles for the position of the errorbars\n",
    "## we can get them from the bin edges building the mean values of a pair of two edges\n",
    "## we can use our known form of indexing for that\n",
    "### plt.errorbar(x-position, y-position, yerr=values, xerr=values, ...)\n",
    "plt.errorbar((edges[:-1]+edges[1:])/2, y=content, yerr=np.sqrt(content), fmt='+', label='uncertainties')\n",
    "\n",
    "# adding the legend and show\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "plt.clf()\n",
    "# errorbar also takes two arrays as yerr input for assymetric errorbars\n",
    "\n",
    "# other useful plot styles: semilogy, semilogx, loglog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uy0ABxFG46Vn"
   },
   "source": [
    "## 4. scipy\n",
    "scipy is useful especially for curve fitting and integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rqtRyiQ546Vp"
   },
   "outputs": [],
   "source": [
    "# we need to import the function curve_fit which implements a least squares algorithm\n",
    "# it is included in the scipy package within the optimize module\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# to fit a gaussian, we define a function taking three parameters in addition to x:\n",
    "def gaussian(x, mu, sigma, I):\n",
    "    return I*np.exp(-(x-mu)*(x-mu)/2/sigma/sigma)\n",
    "\n",
    "# we need the bin middles for the fit\n",
    "xvals = (edges[1:]+edges[:-1])/2\n",
    "yvals = content\n",
    "\n",
    "# the actual fit is pretty straightforward\n",
    "# we define a fit function, the x and y values and curve_fit returns a vector of best parameters\n",
    "# (in our case mu, sigma and I)\n",
    "## the variable covariance contains the covariance matrix of the fit parameters and \n",
    "## can therefore provide us with fit uncertainties\n",
    "params, covariance = curve_fit(gaussian, xvals, yvals)\n",
    "print(params)\n",
    "\n",
    "# more parameters:\n",
    "# - sigma, absolute_sigma: std. dev. of values and whether they are relative or not\n",
    "# - maxfev: number of function evaluations\n",
    "# - p0=[...]: initial values for fit start\n",
    "# - bounds=[[...], [...]] limits for the fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qG17zcBo46V0"
   },
   "source": [
    "### plot fit values\n",
    "you can plot fit results into a figure using for example a np.linspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hzmMW2dQ46V1"
   },
   "outputs": [],
   "source": [
    "# first we create a larger figure\n",
    "plt.figure(figsize=(6,4), dpi=300)\n",
    "\n",
    "# we create a histogram and get its parameters\n",
    "content, edges, hist = plt.hist(x, label='histogram')\n",
    "# add some errorbars in the bin middles\n",
    "plt.errorbar((edges[:-1]+edges[1:])/2, y = content, yerr=np.sqrt(content), fmt='+', label='uncertainties')\n",
    "\n",
    "# create a linspace for plotting the fit results\n",
    "xvals = np.linspace(-3.5, 3.5, 200)\n",
    "\n",
    "# simply plot the results with the * operator\n",
    "plt.plot(xvals, gaussian(xvals, *params), 'k--', label='gaussian fit')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3j4Gqwjc46V8"
   },
   "source": [
    "### Example 4.1: Noisy sine fit\n",
    "Use your noisy sine function from before. Fit a self defined sine function (adding parameters for moving along the x and y axis) and fit a curve on it which is also displayed. \n",
    "Save the figure with a name of your choice.\n",
    "\n",
    "### Example 4.2: Weighted fit\n",
    "Redo the fit of the gaussian histogram above, but use weights this time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0gsqARSX46V-"
   },
   "source": [
    "## 5. pandas\n",
    "easy data import, export and statistical data analysis. pandas is often imported with the alias pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZRBcnf7v46WA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0F2D_kY_46WG"
   },
   "outputs": [],
   "source": [
    "# pandas works with DataFrames, similar to dicts\n",
    "data = pd.DataFrame()\n",
    "\n",
    "data['x'] = np.linspace(0,20, 200)\n",
    "data['y'] = data['x']**2\n",
    "\n",
    "# to get an overview use .head(). \n",
    "# It shows the first five entries of every column, the column name (x,y) and the index\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "# columns can be specified before as well\n",
    "# data = pd.DataFrame(columns=['x', 'y'])\n",
    "\n",
    "plt.figure(figsize=(6,4), dpi=150)\n",
    "plt.plot(data['x'], data['y'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eBn0cP-E46WN"
   },
   "source": [
    "### pandas element access\n",
    "There are several ways to access elements in a pandas DataFrame.\n",
    "The most powerful way is the df.loc[row, column] method.This one can also write new values which column only access can not do! This would lead to a quite cryptic \"write to slice\" warning. You will notice it when you see it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W-DqIJ0L46WO",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# single elements can be accessed best with the loc method\n",
    "print('length',len(data.loc[:, 'x']))\n",
    "print('first data point',data.loc[0, 'x'])\n",
    "\n",
    "# extended selection of data under constraints:\n",
    "# get all values of x where the y values are greater than 370.\n",
    "# contraints = data['y']>370, output column -> 'x'\n",
    "print('values greater then 370')\n",
    "print(data.loc[data['y']>370,'x'])\n",
    "\n",
    "# with two contraints\n",
    "print('values between 190 and 200')\n",
    "print(data.loc[(data['y']<200) & (data['y']>190), 'x'])\n",
    "\n",
    "\n",
    "# data export is very easy as well:\n",
    "data.to_csv('myData.csv')\n",
    "#data.to_excel('myData.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5.0: pandas basics\n",
    "\n",
    "Use the DataFrame data and plot only the following cases:\n",
    "\n",
    "1. all values up to x=2.5\n",
    "2. all values between 50>y<100\n",
    "3. all values between 15>x<17\n",
    "4. all values greater than y=350\n",
    "\n",
    "Use different dashed lines for each plot. Create a new dataframe with the data from the last case and save the data in a csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unique\n",
    "\n",
    "When working with categorical data or features that have discrete values, it is very important to know the number of unique values. It is an essential step towards data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "data['ProtonCounts'] = np.random.randint(0,10, 100)\n",
    "data['NumberofMeasurement']=np.linspace(1,100,100)\n",
    "print(data.ProtonCounts.nunique()) # number of unique value. We expact 10\n",
    "\n",
    "print(data.ProtonCounts.unique()) # unique values that are represented in the list\n",
    "#Attention the order is not sorted\n",
    "\n",
    "#Sometimes it is advantageous to sort your data according to a property.\n",
    "data=data.sort_values(by='ProtonCounts')\n",
    "print(data.head())\n",
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gNNtMGkf46WZ"
   },
   "source": [
    "### import data from xls or csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ENksZWna5C2u"
   },
   "outputs": [],
   "source": [
    "# if you are using Colab, you need to download the file from the github repository first:\n",
    "!wget https://github.com/flome/e4_bsc_python/blob/master/2.%20Important%20Python%20packages%20and%20how%20to%20use%20them/detectors.xls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3nHveSAg46Wa"
   },
   "outputs": [],
   "source": [
    "# DataFrames can be imported and exported from many formats like xls, csv, txt, ...\n",
    "data = pd.read_excel('detectors.xls')\n",
    "\n",
    "# check data content\n",
    "print(data.columns) # print(data.head())\n",
    "\n",
    "# loop over all available columns\n",
    "for col in ['det_0', 'det_1', 'det_2', 'det_3']:\n",
    "    \n",
    "    plt.figure(figsize=(6,4))\n",
    "    \n",
    "    # plot measurement\n",
    "    plt.plot(data['time'], data[col], label='measurement')\n",
    "    \n",
    "    # add legend and show\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHgImiol46Wh"
   },
   "source": [
    "### Example 5.1: Gaussian fit\n",
    "Fit a gaussian function into the data and show the data and the fit on the same plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MNu6Q6BA46Wh"
   },
   "source": [
    "### Another data set\n",
    "Let's have a look at another data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnRlJV5k6h2t"
   },
   "outputs": [],
   "source": [
    "# if you are using Colab, you need to download the file from the github repository first:\n",
    "!wget https://github.com/flome/e4_bsc_python/blob/master/2.%20Important%20Python%20packages%20and%20how%20to%20use%20them/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ns4u8wOl46Wi"
   },
   "outputs": [],
   "source": [
    "# import another data set\n",
    "frame = pd.read_csv('iris.csv')\n",
    "\n",
    "# inspect columns and length of the data frame\n",
    "print(frame.columns)\n",
    "print(len(frame))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gq_DV4RM46Wq"
   },
   "outputs": [],
   "source": [
    "# let's get an overview over the frame entries:\n",
    "for col in frame.columns:\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.hist(frame[col])\n",
    "    plt.ylabel('entries')\n",
    "    plt.xlabel(col)\n",
    "    plt.show()\n",
    "    \n",
    "# How would you get mean value and std of each feature??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fEA15cT846Ww"
   },
   "source": [
    "### Group data by one column\n",
    "Especially when you want to group multiple entries of a data set, you need to be able to group them by a certain column.\n",
    "\n",
    "Naive Approach: Using masks like with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iNN869ZO46W1"
   },
   "outputs": [],
   "source": [
    "# naive approach:\n",
    "group1 = frame[frame['species']=='setosa']\n",
    "group2 = frame[frame['species']=='versicolor']\n",
    "group3 = frame[frame['species']=='virginica']\n",
    "\n",
    "\n",
    "# mean1 = group1.mean()...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMI_zr4_46W_",
    "scrolled": false
   },
   "source": [
    "### groupby and aggregate - might pandas tools\n",
    "pandas can be used for statistical data analysis of a data set. For example the values can be grouped by values in a certain column, for example if a column represents a certain classification group, you can group by that one to see marginalised distributions in each group.\n",
    "\n",
    "With the aggregate method you can gather some statistical information about data sets. Used together with group for example it can be very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "asL1vIOh46XC"
   },
   "outputs": [],
   "source": [
    "# you can group by a column using pandas\n",
    "grouped_frame = frame.groupby(frame['species'])\n",
    "print(grouped_frame.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9zWN8ao146XK"
   },
   "outputs": [],
   "source": [
    "# sometimes you need more than just one statistic measure\n",
    "frame.groupby(frame['species']).aggregate(['mean', 'std', 'sem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NKaY6AOU46XS"
   },
   "outputs": [],
   "source": [
    "# a mighty and useful tool: groupby and aggregate\n",
    "for group, values in frame.groupby('species'):\n",
    "    \n",
    "    # agg is useful to obtain several statistical measures of a data set\n",
    "    print(values.agg(['mean', 'std']))\n",
    "    for col in values.columns:\n",
    "        plt.hist(values[col])\n",
    "        plt.title('%s: %s'%(group, col))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lwneEGkk46XZ"
   },
   "source": [
    "### Example 5.2: Inspect correlations\n",
    "\n",
    "You can inspect correlations in data by plotting features against each other. To be able to differentiate the different species, you can plot the classes in different colors with help of the *color='...'* for matplotlib.pyplot.plot(...).\n",
    "\n",
    "Create at least 3 plots with each one feature against another one. Use different colors to differentiate the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonal distance regression (scipy.odr)\n",
    "\n",
    "In statistics, orthogonal regression (more precisely: orthogonal linear regression) is used to calculate a compensation line for a finite set of metrically scaled data pairs (x(i), y(i)) by the method of least squares. As in other regression models, the sum of the squared distances of the ( x(i), y(i) )from the straight line is minimised. Unlike other forms of linear regression, orthogonal regression does not minimise the distances in x or y direction, but the orthogonal distances. This method does not distinguish between an independent and a dependent variable. \n",
    "\n",
    "Example:\n",
    "independent variable: x\n",
    "dependent variable: y=f(x)=x²\n",
    "\n",
    "Thus, unlike linear regression, applications can be handled where both variables x and y are subject to measurement error. \n",
    "\n",
    "<img src=\"odr.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.odr import *\n",
    "\n",
    "#generate test data\n",
    "n = 40\n",
    "x = np.linspace(0, 10, n)\n",
    "xerr = np.abs(np.random.normal(0, 1.5, n)) # random value from a gaussian distribution (µ, sigma, number of values)\n",
    "x = np.random.normal(x, xerr, n)\n",
    "\n",
    "y = np.linspace(0, 20, n)\n",
    "yerr = np.abs(np.random.normal(0, 1.5, n))\n",
    "y = np.random.normal(y, yerr)\n",
    "\n",
    "def odr_line(p, x): #Attention, input parameters have a special order! \n",
    "    #First: Array of fitparamters p\n",
    "    #Second: Array of x values\n",
    "    \n",
    "    # unpack the parameters from array:\n",
    "    a,b=p\n",
    "    y = a*x+b\n",
    "    return y\n",
    "\n",
    "linear = Model(odr_line) # pass the model to be used. In our case a linear function\n",
    "mydata = RealData(x, y, sx=xerr, sy=yerr) #sx, sy : array_like, optional Standard deviations of x and y \n",
    "myodr = ODR(mydata, linear, beta0=[0,0]) # start parameter are not optional\n",
    "output = myodr.run() # run fit \n",
    "print('Fit parameters',output.beta) # get fit parameters\n",
    "print('Standard deviations',output.sd_beta) # get standard deviation of fit parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5.3: Plotting fit results\n",
    "\n",
    "First plot the x and y values with their standard deviations. Then use the result of the fit and plot it together with the x and y values. As a last step, complete the plot with three sigma bands of the fit with dashed lines and different colours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAJvQry446Xb"
   },
   "source": [
    "## seaborn\n",
    "seaborn is very useful for easy data visualisation and has a lot to offer, we will only have a look at a single feature, the rest is up to you to google ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xR2Es0Ki46Xc"
   },
   "outputs": [],
   "source": [
    "# seaborn is often imported as sns alias\n",
    "import seaborn as sns\n",
    "\n",
    "# let's use the data from the previous example\n",
    "sns.pairplot(frame, hue='species');\n",
    "\n",
    "# Quite impressive, isn't it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0-WNm0qR46Xh"
   },
   "outputs": [],
   "source": [
    "# you can also specify which columns you want to see (of course you can ...)\n",
    "sns.pairplot(frame[['sepal_length', 'sepal_width', 'species']], hue='species');\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "2_Tutorial.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
