{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of the road, where are you going? - Typical architecture choices for some problem types\n",
    "You have learned a lot about how machine learning works and how to build neural network models with Tensorflow and Keras. This is the end of this short tutorial. You will find here a collection of typical learning problems and what kind of neural network model is used often for it. This is not an ultimate guide but rather an overview to give you an idea of what is out there. The choice of architecture, definition of a good loss function, search for a good model with hyperparameter optimization and the decision for the best based on reliable and robus studies will always be up to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Feed-forward* or *dense* neural networks\n",
    "This is the type of neural network model you already know. It works best with data that has some sort of *tabular* form. \n",
    "\n",
    "<p>\n",
    "    <center>\n",
    "        <img src=\"https://www.learnopencv.com/wp-content/uploads/2017/10/mlp-diagram.jpg\" height=250, style=\"height:250px\"> \n",
    "        (image: https://www.learnopencv.com/understanding-feedforward-neural-networks/)\n",
    "    </center>\n",
    "</p>\n",
    "\n",
    "Data which is not in tabular form, e. g. images, need to be transformed to a tabular form before they can be used with *dense* neural networks\n",
    "\n",
    "<p>\n",
    "    <center>\n",
    "        <img src=\"https://www.cntk.ai/jup/cntk103b_MNIST_LR.png\" height=350, style=\"height:350px\"> \n",
    "        (image: https://cntk.ai/pythondocs/CNTK_103B_MNIST_LogisticRegression.html)\n",
    "    </center>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional neural networks\n",
    "*Convolution* layers are different from *dense* layers. Instead of having a weight for every input node, it learns *spatial* correlations in form of *kernels*. A kernel as a certain size, a common size is 3x3. This leads to 10 (=3$\\cdot$3 + bias) trainable parameters for each *input channel*. For example have RGB images three *channels*, one for each color.\n",
    "\n",
    "A convolutional layer can learn more than one kernel given an input. The number of different kernels is called *filters*.\n",
    "\n",
    "\n",
    "<p>\n",
    "    <center>\n",
    "        <img src=\"https://www.cntk.ai/jup/cntk103d_filterset_v2.png\" height=150, style=\"height:150px\"> \n",
    "    </center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    <center>\n",
    "        <img src=\"https://www.cntk.ai/jup/cntk103d_conv2d_final.gif\" height=300, style=\"height:300px\"> \n",
    "        (images: https://cntk.ai/pythondocs/CNTK_103D_MNIST_ConvolutionalNeuralNetwork.html)\n",
    "    </center>\n",
    "</p>\n",
    "\n",
    "Convolutional neural networks are strong if you have data that you think has some 2D or 3D (yes, there are 3D convolutions) *spatial* correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent neural networks\n",
    "*Spatial* correlations are a typical application for convolutional neural network, *temporal* correlations are the domain of *recurrent neural networks*. *Recurrent nodes* have a little bit of memory. They keep their activation for one or more additional incoming data points. Thereby, *later* data is affected by *earlier* data.\n",
    "\n",
    "\n",
    "<p>\n",
    "    <center>\n",
    "        <img src=\"https://upload.wikimedia.org/wikipedia/commons/b/b5/Recurrent_neural_network_unfold.svg\" height=250, style=\"height:250px\"> \n",
    "        (image: https://commons.wikimedia.org/wiki/File:Recurrent_neural_network_unfold.svg)\n",
    "    </center>\n",
    "</p>\n",
    "\n",
    "A typical application of recurrent neural networks are everything related to language processing.\n",
    "\n",
    "<p>\n",
    "    <center>\n",
    "        <img src=\"https://miro.medium.com/max/1248/1*7AHmFKyen8w3mZ3d5BXfig.png\" height=250, style=\"height:250px\"> \n",
    "        (image: https://towardsdatascience.com/understanding-neural-machine-translation-encoder-decoder-architecture-80f205643ba4)\n",
    "    </center>\n",
    "</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial neural networks\n",
    "In many cases it is possible to define a good loss function. We learned in the first tutorial, that a good loss function is the core of every machine learning problem. There are cases though, where defining a meaningful loss is really hard to write down. What is a good loss for example in the case of a neural network that *generates images*? This is really hard to say!\n",
    "*Adversarial networks* are *tandem* models. One part of the model is a neural network that performs a certain task and is mostly built from the previous mentioned building blocks (*dense* layers, *convolutional* layers,...). \n",
    "But now, there is a second network, that also belongs to the model. It is called *adversary* and its job is to provide a meaningful loss for the first network. \n",
    "\n",
    "### Generative adversarial networks\n",
    "One of the most common applications of adversarial network models are generative models. In this area, defining a meaningful loss is really difficult because it is not always defined what a *good generation* looks like. Well... similar to the original data set pretty much!\n",
    "In these cases, generative adversarial network models are trained in the way that the *generator* creates a new sample and the *critic* tries to tell generated from original data set apart. By training both in parallel, the critic becomes better at telling the samples apart and thereby providing a meaningful loss for the generator to improve in turn. By this, the generator can learn to generate samples which are similar to the original distribution.\n",
    "\n",
    "\n",
    "<p>\n",
    "    <center>\n",
    "        <img src=\"https://miro.medium.com/max/1600/0*0_067YjiG3afW-ed.png\" height=350, style=\"height:350px\"> \n",
    "        (image: https://medium.com/machinelearningadvantage/create-any-image-with-c-and-a-generative-adversarial-network-6031a4b90dec)\n",
    "    </center>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    <center>\n",
    "        <img src=\"https://venturebeat.com/wp-content/uploads/2018/09/ccadfbde-1fdc-4c7b-97f6-de16539a335a.png?fit=1644%2C892&strip=all\" height=350, style=\"height:350px\"> \n",
    "        (image: https://venturebeat.com/2018/09/16/nvidia-researchers-develop-ai-system-that-generates-synthetic-scans-of-brain-cancer/)\n",
    "    </center>\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "As generative adversarial networks are merely a *way* to train networks rather than an actual architecture, there are a ton of different ways to implement one. A nice overview can be found here:\n",
    "https://github.com/eriklindernoren/Keras-GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep neural networks\n",
    "Where is the *deep learning* in all of this? *Deep learning* is, as adversarial training, rather a way of how a neural network model is designed. *Deep learning* is about passing *raw features* to a model instead of engineered features. The model is then supposed to learn useful features during the training process itself. This requires of course a huge amount of data.\n",
    "<p>\n",
    "    <center>\n",
    "        <img src=\"https://cdn-images-1.medium.com/max/1000/0*CG13-TBwRo1dHoUi\" height=150 style=\"height:150px\"> \n",
    "        <img src=\"https://cdn-images-1.medium.com/freeze/max/1000/0*4xi8DYFh1a177QuY?q=20\" height=250 style=\"height:250px\"> \n",
    "        <img src=\"https://cdn-images-1.medium.com/freeze/max/1000/0*fiLcoyiOAU-5x0hV?q=20\" height=300 style='height:300px'>\n",
    "        (image: https://mc.ai/deep-learning-background-research/)\n",
    "    </center>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
